{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMwJLnQ7eUOY556LI24/wTe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paraggarg37/Assignment/blob/master/sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0OIw4Txrk_M",
        "outputId": "cd9cac53-8936-488b-a359-705200ed9069"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install torch==1.1.0"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.5.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: torch==1.1.0 in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.1.0) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4dbVeAW14Sk"
      },
      "source": [
        "device = \"cuda:0\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eToxL9u0q3W-"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, freeze_bert = True):\n",
        "        super(SentimentClassifier, self).__init__()\n",
        "        #Instantiating BERT model object \n",
        "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
        "        \n",
        "        #Freeze bert layers\n",
        "        if freeze_bert:\n",
        "            for p in self.bert_layer.parameters():\n",
        "                p.requires_grad = False\n",
        "        \n",
        "        #Classification layer\n",
        "        self.cls_layer = nn.Linear(768, 1).to(device)\n",
        "\n",
        "    def forward(self, seq, attn_masks):\n",
        "        '''\n",
        "        Inputs:\n",
        "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
        "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
        "        '''\n",
        "\n",
        "        #Feeding the input to BERT model to obtain contextualized representations\n",
        "        #cont_reps, _ = self.bert_layer(seq, attention_mask = attn_masks)\n",
        "\n",
        "        #Obtaining the representation of [CLS] head\n",
        "        #print(cont_reps)\n",
        "        #cls_rep = cont_reps[:, 0]\n",
        "        out = self.bert_layer(seq, attention_mask = attn_masks)\n",
        "\n",
        "        #Feeding cls_rep to the classifier layer\n",
        "        #logits = self.cls_layer(out[1])\n",
        "      \n",
        "        logits = self.cls_layer(out[0][:,0])\n",
        "\n",
        "        return logits"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_yrhXzzq_rj"
      },
      "source": [
        "net = SentimentClassifier(freeze_bert = True).to(device)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MSLxJA1q34a"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "opti = optim.Adam(net.parameters(), lr = 2e-5)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1YskKQLrFjI"
      },
      "source": [
        "def train(net, criterion, opti, train_loader, val_loader, args):\n",
        "    for ep in range(args.max_eps):\n",
        "        print (\"Running ep : {}\".format(ep))\n",
        "        \n",
        "        for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
        "            #print (\"Running batch : {}\".format(it))\n",
        "            #Clear gradients\n",
        "            opti.zero_grad()  \n",
        "            #Converting these to cuda tensors\n",
        "            seq, attn_masks, labels = seq.to(args.gpu), attn_masks.to(args.gpu), labels.to(args.gpu)\n",
        "\n",
        "            #Obtaining the logits from the model\n",
        "            logits = net(seq, attn_masks)\n",
        "\n",
        "            #Computing loss\n",
        "            loss = criterion(logits.squeeze(-1), labels.float())\n",
        "\n",
        "            #Backpropagating the gradients\n",
        "            loss.backward()\n",
        "\n",
        "            #Optimization step\n",
        "            opti.step()\n",
        "\n",
        "            if (it + 1) % args.print_every == 0:\n",
        "                acc = get_accuracy_from_logits(logits, labels)\n",
        "                print(\"Iteration {} of epoch {} complete. Loss : {} Accuracy : {}\".format(it+1, ep+1, loss.item(), acc))\n",
        "        \n",
        "        val_acc, val_loss = evaluate(net, criterion, val_loader, args)\n",
        "        print(\"Epoch {} complete! Validation Accuracy : {}, Validation Loss : {}\".format(ep, val_acc, val_loss))\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqAxu64rrKF_"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import BertTokenizer\n",
        "import pandas as pd\n",
        "\n",
        "class SSTDataset(Dataset):\n",
        "\n",
        "    def __init__(self, filename, maxlen):\n",
        "\n",
        "        #Store the contents of the file in a pandas dataframe\n",
        "        self.df = pd.read_csv(filename, delimiter = '\\t')\n",
        "\n",
        "        #Initialize the BERT tokenizer\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.maxlen = maxlen\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        #print(\"calinng get item\")\n",
        "        #print(self.df.loc)\n",
        "        #Selecting the sentence and label at the specified index in the data frame\n",
        "        sentence = self.df.loc[index, self.df.columns[0]]\n",
        "        #print(\"calinng get item done\")\n",
        "        label = self.df.loc[index, self.df.columns[1]]\n",
        "\n",
        "        #Preprocessing the text to be suitable for BERT\n",
        "        tokens = self.tokenizer.tokenize(sentence) #Tokenize the sentence\n",
        "        tokens = ['[CLS]'] + tokens + ['[SEP]'] #Insering the CLS and SEP token in the beginning and end of the sentence\n",
        "        if len(tokens) < self.maxlen:\n",
        "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] #Padding sentences\n",
        "        else:\n",
        "            tokens = tokens[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n",
        "\n",
        "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens) #Obtaining the indices of the tokens in the BERT Vocabulary\n",
        "        tokens_ids_tensor = torch.tensor(tokens_ids) #Converting the list to a pytorch tensor\n",
        "\n",
        "        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n",
        "        attn_mask = (tokens_ids_tensor != 0).long()\n",
        "\n",
        "        return tokens_ids_tensor, attn_mask, label"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZMle6N1vAw0"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfcKHuXsrN1b"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "#Creating instances of training and validation set\n",
        "train_set = SSTDataset(filename = 'train.tsv', maxlen = 30)\n",
        "val_set = SSTDataset(filename = 'dev.tsv', maxlen = 30)\n",
        "\n",
        "#Creating intsances of training and validation dataloaders\n",
        "train_loader = DataLoader(train_set, batch_size = 64, num_workers = 5)\n",
        "val_loader = DataLoader(val_set, batch_size = 64, num_workers = 5)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shYVkxMPtHR9",
        "outputId": "595754cd-882f-436d-ee31-eedaa4e0e378"
      },
      "source": [
        "train_loader"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f542e13c890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J9UWCLLrRfc"
      },
      "source": [
        "class Args():\n",
        "    def __init__(self):\n",
        "        self.max_eps = 50\n",
        "        self.gpu = device\n",
        "        self.print_every = 30"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItBplmXqrape"
      },
      "source": [
        "args = Args()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWLv6N--rdi6",
        "outputId": "db0e361f-793b-49f1-b7c1-dfa53f4faa9b"
      },
      "source": [
        "train(net, criterion, opti, train_loader, val_loader, args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running ep : 0\n",
            "Iteration 30 of epoch 1 complete. Loss : 0.6787721514701843 Accuracy : 0.5625\n",
            "Iteration 60 of epoch 1 complete. Loss : 0.6796607971191406 Accuracy : 0.5625\n",
            "Iteration 90 of epoch 1 complete. Loss : 0.6950100660324097 Accuracy : 0.453125\n",
            "Epoch 0 complete! Validation Accuracy : 0.5466517806053162, Validation Loss : 0.6803450754710606\n",
            "Running ep : 1\n",
            "Iteration 30 of epoch 2 complete. Loss : 0.6707484722137451 Accuracy : 0.609375\n",
            "Iteration 60 of epoch 2 complete. Loss : 0.6688879728317261 Accuracy : 0.609375\n",
            "Iteration 90 of epoch 2 complete. Loss : 0.6851829290390015 Accuracy : 0.5\n",
            "Epoch 1 complete! Validation Accuracy : 0.5986607670783997, Validation Loss : 0.6710948135171618\n",
            "Running ep : 2\n",
            "Iteration 30 of epoch 3 complete. Loss : 0.6619623899459839 Accuracy : 0.6875\n",
            "Iteration 60 of epoch 3 complete. Loss : 0.6589871644973755 Accuracy : 0.65625\n",
            "Iteration 90 of epoch 3 complete. Loss : 0.6763014793395996 Accuracy : 0.53125\n",
            "Epoch 2 complete! Validation Accuracy : 0.6310268640518188, Validation Loss : 0.662321652684893\n",
            "Running ep : 3\n",
            "Iteration 30 of epoch 4 complete. Loss : 0.6531776189804077 Accuracy : 0.71875\n",
            "Iteration 60 of epoch 4 complete. Loss : 0.6496071219444275 Accuracy : 0.6875\n",
            "Iteration 90 of epoch 4 complete. Loss : 0.6679486036300659 Accuracy : 0.578125\n",
            "Epoch 3 complete! Validation Accuracy : 0.6662946939468384, Validation Loss : 0.6539337762764522\n",
            "Running ep : 4\n",
            "Iteration 30 of epoch 5 complete. Loss : 0.644627034664154 Accuracy : 0.734375\n",
            "Iteration 60 of epoch 5 complete. Loss : 0.6406404972076416 Accuracy : 0.6875\n",
            "Iteration 90 of epoch 5 complete. Loss : 0.6599932312965393 Accuracy : 0.609375\n",
            "Epoch 4 complete! Validation Accuracy : 0.6895089745521545, Validation Loss : 0.645892437015261\n",
            "Running ep : 5\n",
            "Iteration 30 of epoch 6 complete. Loss : 0.6363686323165894 Accuracy : 0.734375\n",
            "Iteration 60 of epoch 6 complete. Loss : 0.6320407390594482 Accuracy : 0.703125\n",
            "Iteration 90 of epoch 6 complete. Loss : 0.652381420135498 Accuracy : 0.640625\n",
            "Epoch 5 complete! Validation Accuracy : 0.7095982432365417, Validation Loss : 0.6381727499621255\n",
            "Running ep : 6\n",
            "Iteration 30 of epoch 7 complete. Loss : 0.6284087896347046 Accuracy : 0.78125\n",
            "Iteration 60 of epoch 7 complete. Loss : 0.623779833316803 Accuracy : 0.71875\n",
            "Iteration 90 of epoch 7 complete. Loss : 0.6450833678245544 Accuracy : 0.65625\n",
            "Epoch 6 complete! Validation Accuracy : 0.7352678775787354, Validation Loss : 0.63075504558427\n",
            "Running ep : 7\n",
            "Iteration 30 of epoch 8 complete. Loss : 0.6207385063171387 Accuracy : 0.78125\n",
            "Iteration 60 of epoch 8 complete. Loss : 0.6158369779586792 Accuracy : 0.71875\n",
            "Iteration 90 of epoch 8 complete. Loss : 0.6380776166915894 Accuracy : 0.6875\n",
            "Epoch 7 complete! Validation Accuracy : 0.7419642806053162, Validation Loss : 0.6236221279416766\n",
            "Running ep : 8\n",
            "Iteration 30 of epoch 9 complete. Loss : 0.613345205783844 Accuracy : 0.796875\n",
            "Iteration 60 of epoch 9 complete. Loss : 0.6081941723823547 Accuracy : 0.75\n",
            "Iteration 90 of epoch 9 complete. Loss : 0.6313461065292358 Accuracy : 0.703125\n",
            "Epoch 8 complete! Validation Accuracy : 0.7497767806053162, Validation Loss : 0.6167584231921605\n",
            "Running ep : 9\n",
            "Iteration 30 of epoch 10 complete. Loss : 0.6062153577804565 Accuracy : 0.8125\n",
            "Iteration 60 of epoch 10 complete. Loss : 0.6008355617523193 Accuracy : 0.75\n",
            "Iteration 90 of epoch 10 complete. Loss : 0.6248732209205627 Accuracy : 0.703125\n",
            "Epoch 9 complete! Validation Accuracy : 0.7571429014205933, Validation Loss : 0.6101496091910771\n",
            "Running ep : 10\n",
            "Iteration 30 of epoch 11 complete. Loss : 0.599335789680481 Accuracy : 0.828125\n",
            "Iteration 60 of epoch 11 complete. Loss : 0.5937464833259583 Accuracy : 0.78125\n",
            "Iteration 90 of epoch 11 complete. Loss : 0.6186442971229553 Accuracy : 0.734375\n",
            "Epoch 10 complete! Validation Accuracy : 0.7638393640518188, Validation Loss : 0.6037823132106236\n",
            "Running ep : 11\n",
            "Iteration 30 of epoch 12 complete. Loss : 0.5926941633224487 Accuracy : 0.84375\n",
            "Iteration 60 of epoch 12 complete. Loss : 0.5869132280349731 Accuracy : 0.796875\n",
            "Iteration 90 of epoch 12 complete. Loss : 0.6126460433006287 Accuracy : 0.78125\n",
            "Epoch 11 complete! Validation Accuracy : 0.7694197297096252, Validation Loss : 0.5976440991674151\n",
            "Running ep : 12\n",
            "Iteration 30 of epoch 13 complete. Loss : 0.5862784385681152 Accuracy : 0.84375\n",
            "Iteration 60 of epoch 13 complete. Loss : 0.5803231000900269 Accuracy : 0.828125\n",
            "Iteration 90 of epoch 13 complete. Loss : 0.6068658828735352 Accuracy : 0.796875\n",
            "Epoch 12 complete! Validation Accuracy : 0.7801339626312256, Validation Loss : 0.5917232930660248\n",
            "Running ep : 13\n",
            "Iteration 30 of epoch 14 complete. Loss : 0.580077588558197 Accuracy : 0.84375\n",
            "Iteration 60 of epoch 14 complete. Loss : 0.5739642977714539 Accuracy : 0.84375\n",
            "Iteration 90 of epoch 14 complete. Loss : 0.6012923717498779 Accuracy : 0.796875\n",
            "Epoch 13 complete! Validation Accuracy : 0.7845982313156128, Validation Loss : 0.5860090851783752\n",
            "Running ep : 14\n",
            "Iteration 30 of epoch 15 complete. Loss : 0.5740810632705688 Accuracy : 0.828125\n",
            "Iteration 60 of epoch 15 complete. Loss : 0.5678256750106812 Accuracy : 0.84375\n",
            "Iteration 90 of epoch 15 complete. Loss : 0.5959146022796631 Accuracy : 0.8125\n",
            "Epoch 14 complete! Validation Accuracy : 0.7879464626312256, Validation Loss : 0.5804912235055651\n",
            "Running ep : 15\n",
            "Iteration 30 of epoch 16 complete. Loss : 0.5682790279388428 Accuracy : 0.84375\n",
            "Iteration 60 of epoch 16 complete. Loss : 0.5618967413902283 Accuracy : 0.84375\n",
            "Iteration 90 of epoch 16 complete. Loss : 0.590722382068634 Accuracy : 0.8125\n",
            "Epoch 15 complete! Validation Accuracy : 0.7946428656578064, Validation Loss : 0.5751602394240243\n",
            "Running ep : 16\n",
            "Iteration 30 of epoch 17 complete. Loss : 0.5626621246337891 Accuracy : 0.859375\n",
            "Iteration 60 of epoch 17 complete. Loss : 0.556167721748352 Accuracy : 0.84375\n",
            "Iteration 90 of epoch 17 complete. Loss : 0.5857064723968506 Accuracy : 0.8125\n",
            "Epoch 16 complete! Validation Accuracy : 0.7991071939468384, Validation Loss : 0.5700071156024933\n",
            "Running ep : 17\n",
            "Iteration 30 of epoch 18 complete. Loss : 0.5572217106819153 Accuracy : 0.859375\n",
            "Iteration 60 of epoch 18 complete. Loss : 0.5506293773651123 Accuracy : 0.84375\n",
            "Iteration 90 of epoch 18 complete. Loss : 0.5808578729629517 Accuracy : 0.8125\n",
            "Epoch 17 complete! Validation Accuracy : 0.8046875596046448, Validation Loss : 0.5650235201631274\n",
            "Running ep : 18\n",
            "Iteration 30 of epoch 19 complete. Loss : 0.5519495010375977 Accuracy : 0.859375\n",
            "Iteration 60 of epoch 19 complete. Loss : 0.5452732443809509 Accuracy : 0.84375\n",
            "Iteration 90 of epoch 19 complete. Loss : 0.576168417930603 Accuracy : 0.8125\n",
            "Epoch 18 complete! Validation Accuracy : 0.8080357313156128, Validation Loss : 0.5602015640054431\n",
            "Running ep : 19\n",
            "Iteration 30 of epoch 20 complete. Loss : 0.5468378663063049 Accuracy : 0.875\n",
            "Iteration 60 of epoch 20 complete. Loss : 0.5400910377502441 Accuracy : 0.84375\n",
            "Iteration 90 of epoch 20 complete. Loss : 0.5716304779052734 Accuracy : 0.8125\n",
            "Epoch 19 complete! Validation Accuracy : 0.8102678656578064, Validation Loss : 0.5555338774408612\n",
            "Running ep : 20\n",
            "Iteration 30 of epoch 21 complete. Loss : 0.5418794751167297 Accuracy : 0.875\n",
            "Iteration 60 of epoch 21 complete. Loss : 0.5350751280784607 Accuracy : 0.84375\n",
            "Iteration 90 of epoch 21 complete. Loss : 0.5672366619110107 Accuracy : 0.8125\n",
            "Epoch 20 complete! Validation Accuracy : 0.8113839626312256, Validation Loss : 0.5510135165282658\n",
            "Running ep : 21\n",
            "Iteration 30 of epoch 22 complete. Loss : 0.5370674729347229 Accuracy : 0.875\n",
            "Iteration 60 of epoch 22 complete. Loss : 0.5302183628082275 Accuracy : 0.84375\n",
            "Iteration 90 of epoch 22 complete. Loss : 0.5629802346229553 Accuracy : 0.8125\n",
            "Epoch 21 complete! Validation Accuracy : 0.8180803656578064, Validation Loss : 0.5466339630740029\n",
            "Running ep : 22\n",
            "Iteration 30 of epoch 23 complete. Loss : 0.5323954820632935 Accuracy : 0.875\n",
            "Iteration 60 of epoch 23 complete. Loss : 0.5255140066146851 Accuracy : 0.84375\n",
            "Iteration 90 of epoch 23 complete. Loss : 0.5588549375534058 Accuracy : 0.8125\n",
            "Epoch 22 complete! Validation Accuracy : 0.8180803656578064, Validation Loss : 0.5423891076019832\n",
            "Running ep : 23\n",
            "Iteration 30 of epoch 24 complete. Loss : 0.5278574228286743 Accuracy : 0.875\n",
            "Iteration 60 of epoch 24 complete. Loss : 0.5209555625915527 Accuracy : 0.84375\n",
            "Iteration 90 of epoch 24 complete. Loss : 0.5548546314239502 Accuracy : 0.8125\n",
            "Epoch 23 complete! Validation Accuracy : 0.8196429014205933, Validation Loss : 0.5382731769766126\n",
            "Running ep : 24\n",
            "Iteration 30 of epoch 25 complete. Loss : 0.5234475135803223 Accuracy : 0.890625\n",
            "Iteration 60 of epoch 25 complete. Loss : 0.5165371298789978 Accuracy : 0.84375\n",
            "Iteration 90 of epoch 25 complete. Loss : 0.5509740114212036 Accuracy : 0.8125\n",
            "Epoch 24 complete! Validation Accuracy : 0.822991132736206, Validation Loss : 0.5342807684625898\n",
            "Running ep : 25\n",
            "Iteration 30 of epoch 26 complete. Loss : 0.5191605091094971 Accuracy : 0.890625\n",
            "Iteration 60 of epoch 26 complete. Loss : 0.512252926826477 Accuracy : 0.84375\n",
            "Iteration 90 of epoch 26 complete. Loss : 0.5472075939178467 Accuracy : 0.8125\n",
            "Epoch 25 complete! Validation Accuracy : 0.8241072297096252, Validation Loss : 0.5304067262581417\n",
            "Running ep : 26\n",
            "Iteration 30 of epoch 27 complete. Loss : 0.5149911642074585 Accuracy : 0.890625\n",
            "Iteration 60 of epoch 27 complete. Loss : 0.5080975294113159 Accuracy : 0.859375\n",
            "Iteration 90 of epoch 27 complete. Loss : 0.5435504913330078 Accuracy : 0.8125\n",
            "Epoch 26 complete! Validation Accuracy : 0.8263393640518188, Validation Loss : 0.5266462564468384\n",
            "Running ep : 27\n",
            "Iteration 30 of epoch 28 complete. Loss : 0.5109347701072693 Accuracy : 0.890625\n",
            "Iteration 60 of epoch 28 complete. Loss : 0.5040659308433533 Accuracy : 0.859375\n",
            "Iteration 90 of epoch 28 complete. Loss : 0.5399981141090393 Accuracy : 0.8125\n",
            "Epoch 27 complete! Validation Accuracy : 0.8274554014205933, Validation Loss : 0.5229947950158801\n",
            "Running ep : 28\n",
            "Iteration 30 of epoch 29 complete. Loss : 0.5069867372512817 Accuracy : 0.890625\n",
            "Iteration 60 of epoch 29 complete. Loss : 0.5001533031463623 Accuracy : 0.859375\n",
            "Iteration 90 of epoch 29 complete. Loss : 0.536545991897583 Accuracy : 0.8125\n",
            "Epoch 28 complete! Validation Accuracy : 0.8263393640518188, Validation Loss : 0.5194480546883175\n",
            "Running ep : 29\n",
            "Iteration 30 of epoch 30 complete. Loss : 0.5031429529190063 Accuracy : 0.890625\n",
            "Iteration 60 of epoch 30 complete. Loss : 0.4963550269603729 Accuracy : 0.859375\n",
            "Iteration 90 of epoch 30 complete. Loss : 0.533190131187439 Accuracy : 0.796875\n",
            "Epoch 29 complete! Validation Accuracy : 0.8274554014205933, Validation Loss : 0.5160019674471447\n",
            "Running ep : 30\n",
            "Iteration 30 of epoch 31 complete. Loss : 0.4993991255760193 Accuracy : 0.890625\n",
            "Iteration 60 of epoch 31 complete. Loss : 0.4926667809486389 Accuracy : 0.859375\n",
            "Iteration 90 of epoch 31 complete. Loss : 0.529926598072052 Accuracy : 0.796875\n",
            "Epoch 30 complete! Validation Accuracy : 0.8285714983940125, Validation Loss : 0.5126526653766632\n",
            "Running ep : 31\n",
            "Iteration 30 of epoch 32 complete. Loss : 0.4957515001296997 Accuracy : 0.890625\n",
            "Iteration 60 of epoch 32 complete. Loss : 0.48908454179763794 Accuracy : 0.859375\n",
            "Iteration 90 of epoch 32 complete. Loss : 0.5267515778541565 Accuracy : 0.796875\n",
            "Epoch 31 complete! Validation Accuracy : 0.8285714983940125, Validation Loss : 0.5093965147222791\n",
            "Running ep : 32\n",
            "Iteration 30 of epoch 33 complete. Loss : 0.4921964704990387 Accuracy : 0.890625\n",
            "Iteration 60 of epoch 33 complete. Loss : 0.4856042265892029 Accuracy : 0.859375\n",
            "Iteration 90 of epoch 33 complete. Loss : 0.5236617922782898 Accuracy : 0.796875\n",
            "Epoch 32 complete! Validation Accuracy : 0.8285714983940125, Validation Loss : 0.5062300477709089\n",
            "Running ep : 33\n",
            "Iteration 30 of epoch 34 complete. Loss : 0.4887305200099945 Accuracy : 0.890625\n",
            "Iteration 60 of epoch 34 complete. Loss : 0.4822222888469696 Accuracy : 0.859375\n",
            "Iteration 90 of epoch 34 complete. Loss : 0.5206539630889893 Accuracy : 0.796875\n",
            "Epoch 33 complete! Validation Accuracy : 0.8285714983940125, Validation Loss : 0.5031499926533017\n",
            "Running ep : 34\n",
            "Iteration 30 of epoch 35 complete. Loss : 0.48535048961639404 Accuracy : 0.890625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDniGTeW9b-b"
      },
      "source": [
        "def evaluate(net, criterion, dataloader, args):\n",
        "    net.eval()\n",
        "\n",
        "    mean_acc, mean_loss = 0, 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for seq, attn_masks, labels in dataloader:\n",
        "            seq, attn_masks, labels = seq.to(device), attn_masks.to(device), labels.torch(device)\n",
        "            logits = net(seq, attn_masks)\n",
        "            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n",
        "            mean_acc += get_accuracy_from_logits(logits, labels)\n",
        "            count += 1\n",
        "\n",
        "    return mean_acc / count, mean_loss / count"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH504p1T7p6e"
      },
      "source": [
        "def get_accuracy_from_logits(logits, labels):\n",
        "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
        "    soft_probs = (probs > 0.5).long()\n",
        "    acc = (soft_probs.squeeze() == labels).float().mean()\n",
        "    return acc"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19hcASXor83w"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/clairett/pytorch-sentiment-classification/master/data/SST2/test.tsv "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8o_PmPWtVE9"
      },
      "source": [
        "df = pd.read_csv('train.tsv', delimiter = '\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URC96Fy5vB3L"
      },
      "source": [
        "print (df.loc[0,df.columns[1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dju3RNixkmj"
      },
      "source": [
        "#https://medium.com/swlh/painless-fine-tuning-of-bert-in-pytorch-b91c14912caa#:~:text=The%20from_pretrained%20method%20creates%20an,like%20any%20other%20Pytorch%20module."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}